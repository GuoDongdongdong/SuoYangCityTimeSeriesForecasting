# Any key should not be changed.

[CommonArgs]
dataset_file_dir  = str:TIEGAN_dataset
dataset_file_name = str:humidity.csv
model             = str:Autoformer
# train_test is True mean that train and test, otherwise only test.
train_test        = bool:True
model_save_path   = str:log\MPformer\20241227_T163102\checkpoints.pth
# mutli target should be T1,T2,T3...
targets           = list:humidity
date_frequence    = str:h
timeenc           = str:timeF
lookback_length   = int:384
predict_length    = int:48
# label_length should half of lookback_length
label_length      = str:None
train_ratio       = float:0.7
vali_ratio        = float:0.1
random_seed       = int:202221543
use_gpu           = bool:True
use_multi_gpu     = bool:False
# multi_GPU_id should be like 0,1,2,3...
gpu_id            = str:0
use_amp           = bool:False
batch_size        = int:32
lr                = float:1e-4
epochs            = int:200
patience          = int:5
num_workers       = int:0
dropout           = float:0.1
# Model Args

# Transofmer-based
[MPformer]
patch_length  = int:16
patch_stride  = int:8
e_layers      = int:2
n_heads       = int:8
d_model       = int:512
d_ff          = int:512
activate_type = str:gelu
norm_type     = str:batch
[Autoformer]
embed            = str:timeF
output_attention = int:0
moving_avg       = int:25
d_model          = int:512
factor           = int:1
n_heads          = int:8
e_layers         = int:2
d_layers         = int:1
d_ff             = int:512
activation       = str:gelu
revin            = int:1
subtract_last    = int:0
affine           = int:1
[FEDformer]
modes            = int:64
version          = str:Fourier
mode_select      = str:random
l                = int:3
base             = str:legendre
cross_activation = str:tanh
embed            = str:timeF
d_model          = int:512
d_ff             = int:512
n_heads          = int:8
e_layers         = int:2
d_layers         = int:1
activation       = str:gelu
moving_avg       = int:25
output_attention = int:0
[PatchTST]
e_layers      = int:2
n_heads       = int:8
d_model       = int:512
d_ff          = int:512
fc_dropout    = float:0.05
head_dropout  = float:0
individual    = int:0
patch_len     = int:16
stride        = int:8
padding_patch = str:end
revin         = int:1
affine        = int:0
subtract_last = int:0
kernel_size   = int:25
decomposition = int:0
[Informer]
embed = str:Fixed
distil = int:1
d_model = int:512
factor = int:5
n_heads = int:8
e_layers = int:2
d_layers = int:1
d_ff = int:512
activation = str:gelu
output_attention = int:0
[Transformer]
embed            = str:timeF
factor           = int:5
n_heads          = int:8
e_layers         = int:2
d_layers         = int:1
d_model          = int:512
d_ff             = int:512
activation       = str:gelu
output_attention = int:0

# Linear-based
[DLinear]
individual = int:1
[NLinear]
individual = int:1

# RNN GRU LSTM-based
[LSTM]
dimension = int:1
hidden_size = int:256
num_layers = int:2
bidirectional = int:0

# Statistical-based
[ARIMA]